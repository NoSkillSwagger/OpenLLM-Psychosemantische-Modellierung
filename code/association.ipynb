{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd93d94f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import ollama\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daedb4fb",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e14b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SWOW-style prompt template\n",
    "PROMPT_TEMPLATE = \"\"\"<<SYS>>\n",
    "You MUST follow these rules:\n",
    "\n",
    "1. Do NOT output reasoning, chain-of-thought, thinking process, analysis,\n",
    "   hidden thoughts, XML tags like <think>, or any extra formatting.\n",
    "2. Output ONLY one single line with exactly four semicolon-separated fields.\n",
    "3. Format: cue;A1;A2;A3\n",
    "4. A1-A3 MUST be exactly one word each (no spaces).\n",
    "5. If you cannot generate A2 or A3, use exactly: No more responses\n",
    "6. Any extra text makes the output INVALID.\n",
    "\n",
    "<</SYS>>\n",
    "\n",
    "You will perform a word association task.\n",
    "\n",
    "Task:\n",
    "Given a cue word, produce up to three single-word associations:\n",
    "A1 = strongest association\n",
    "A2 = second association\n",
    "A3 = third association\n",
    "\n",
    "Output format (MANDATORY):\n",
    "cue;A1;A2;A3\n",
    "\n",
    "Cue:\n",
    "{cue}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04348a3b",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a1b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# FUNCTION TO QUERY OLLAMA\n",
    "# ----------------------------------------------------------\n",
    "def ask_ollama(model: str, prompt: str) -> str:\n",
    "    result = ollama.generate(model=model, prompt=prompt)\n",
    "    return result['response']\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# LOAD INPUT WORDS\n",
    "# ----------------------------------------------------------\n",
    "def load_cue_words(path: str):\n",
    "    with open(path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        return [row[0] for row in reader]  # first column only\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# SAVE OUTPUT\n",
    "# ----------------------------------------------------------\n",
    "def save_results(path: str, rows):\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"model\", \"cue\", \"A1\", \"A2\", \"A3\"])\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123fcc6d",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97609f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(cues, output, model):\n",
    "    results = []\n",
    "    for cue in cues:\n",
    "        prompt = PROMPT_TEMPLATE.format(cue=cue)\n",
    "        response = ask_ollama(model, prompt)\n",
    "        if response is None:\n",
    "            continue\n",
    "\n",
    "        # Now split by semicolon\n",
    "        parts = [p.strip() for p in response.split(\";\")]\n",
    "\n",
    "        if len(parts) != 4:\n",
    "            print(f\"Warning: Unexpected format for '{cue}': {response}\")\n",
    "            continue\n",
    "\n",
    "        cue_out, a1, a2, a3 = parts\n",
    "        results.append([model, cue_out, a1, a2, a3])\n",
    "\n",
    "    save_results(output, results)\n",
    "    print(f\"Done! Saved to {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.join(\"..\", \"data\", \"datasets\", \"cues_random_100.csv\")\n",
    "cues = load_cue_words(input_path)\n",
    "\n",
    "#models = ['qwen3:8b', 'qwen3:14b', 'qwen3:30b', 'gemma3:4b', 'gemma3:12b', 'gemma3:27b', 'llama3.1:8b']\n",
    "models = ['qwen3:14b']\n",
    "\n",
    "for model in models:\n",
    "    output_path = os.path.join(\"..\", \"data\", \"results\", f'{model.replace(':', '_').replace('.', '_')}_associations.csv')\n",
    "    print(f\"Starting with model: {model}\")\n",
    "    run_experiment(cues, output_path, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17fda10",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506654d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_values(input_csv, output_csv, column_name, delimiter=\",\"):\n",
    "    \"\"\"\n",
    "    Extracts all distinct values from a given column in a CSV file and writes them\n",
    "    into a new CSV file (one value per line).\n",
    "    \n",
    "    Args:\n",
    "        input_csv (str): Path to the input CSV file.\n",
    "        output_csv (str): Path to the output CSV file.\n",
    "        column_name (str): Name of the column from which to collect unique values.\n",
    "        delimiter (str): CSV delimiter (default=\",\").\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of unique values.\n",
    "    \"\"\"\n",
    "    unique_values = set()\n",
    "\n",
    "    # Read input CSV\n",
    "    with open(input_csv, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f, delimiter=delimiter)\n",
    "        if column_name not in reader.fieldnames:\n",
    "            raise ValueError(f\"Column '{column_name}' not found in CSV.\")\n",
    "        \n",
    "        for row in reader:\n",
    "            value = row[column_name].strip()\n",
    "            if value:\n",
    "                unique_values.add(value)\n",
    "\n",
    "    # Sort for consistent output\n",
    "    unique_list = sorted(unique_values)\n",
    "\n",
    "    # Write output CSV\n",
    "    with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter=delimiter)\n",
    "        writer.writerow([column_name])  # header\n",
    "        for val in unique_list:\n",
    "            writer.writerow([val])\n",
    "\n",
    "    return unique_list\n",
    "\n",
    "extract_unique_values(r\"C:\\Users\\peers\\Downloads\\SWOW-EN18\\SWOW-EN.complete.20180827.csv\", \"cues.csv\", \"cue\", \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a4bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Load all cue words\n",
    "all_cues = load_cue_words(\"cues.csv\")\n",
    "\n",
    "# Select random subset of 100\n",
    "random_subset = random.sample(all_cues, min(100, len(all_cues)))\n",
    "\n",
    "# Save to new CSV\n",
    "output_file = \"cues_random_100.csv\"\n",
    "with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"cue\"])  # header\n",
    "    for cue in random_subset:\n",
    "        writer.writerow([cue])\n",
    "\n",
    "print(f\"Saved {len(random_subset)} random cue words to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c13c9e3",
   "metadata": {},
   "source": [
    "# Response Strength Analysis\n",
    "\n",
    "Response strength measures how dominant/consistent a response is for a given cue.\n",
    "- **Strength = frequency of response / total number of responses for that cue**\n",
    "- Higher strength = that response is the clear winner for that cue\n",
    "- Lower strength = responses are more evenly distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a0977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 483636 cue-response pairs from SWOW R1\n",
      "Loaded 978908 cue-response pairs from SWOW R123\n",
      "\n",
      "Found 7 model files\n",
      "Loading A1 responses from gemma3_12b...\n",
      "Loading A1 responses from gemma3_27b...\n",
      "Loading A1 responses from gemma3_4b...\n",
      "Loading A1 responses from llama3_1_8b...\n",
      "Loading A1 responses from qwen3_14b...\n",
      "Loading A1 responses from qwen3_30b...\n",
      "Loading A1 responses from qwen3_8b...\n",
      "\n",
      "================================================================================\n",
      "Consolidated A1 response strength comparison saved to:\n",
      "../data/results/model_a1_vs_swow_strength.csv\n",
      "================================================================================\n",
      "\n",
      "Total unique cue-response pairs: 429\n",
      "Total unique cues: 204\n",
      "\n",
      "First 20 rows:\n",
      "       cue   response  model_count  total_models  model_strength swow_r1_strength swow_r123_strength\n",
      "    absorb     sponge            1             7        0.142857            0.258              0.145\n",
      "    active  energetic            1             7        0.142857             0.07              0.055\n",
      "  airplane     flight            1             7        0.142857              0.1              0.071\n",
      "     algae      green            2             7        0.285714            0.367              0.243\n",
      "     algae      ocean            2             7        0.285714             0.01              0.025\n",
      "     algae      water            1             7        0.142857            0.041              0.081\n",
      "     amass    collect            2             7        0.285714            0.189              0.102\n",
      "     amass accumulate            1             7        0.142857            0.089              0.049\n",
      "     amass     gather            1             7        0.142857            0.278              0.168\n",
      "     amass     wealth            1             7        0.142857            0.033              0.062\n",
      "archeology        dig            1             7        0.142857             0.18              0.107\n",
      "archeology  Egyptians            1             7        0.142857             n.a.               n.a.\n",
      "archeology    digging            1             7        0.142857             0.06              0.057\n",
      "archeology      study            1             7        0.142857             0.06               0.04\n",
      "archeology    history            1             7        0.142857             0.07               0.05\n",
      "archeology  artifacts            1             7        0.142857             n.a.              0.007\n",
      "   ashtray cigarettes            1             7        0.142857            0.082              0.047\n",
      "   atheism     belief            2             7        0.285714             0.02              0.018\n",
      "   atheism  disbelief            1             7        0.142857             0.01              0.007\n",
      "   atheism  nonbelief            1             7        0.142857             0.01              0.004\n",
      "\n",
      "\n",
      "Column Explanation:\n",
      "--------------------------------------------------------------------------------\n",
      "cue                : The cue word\n",
      "response           : The A1 (first) response from models\n",
      "model_count        : How many models gave this response\n",
      "total_models       : Total number of models analyzed\n",
      "model_strength     : Proportion of models that gave this response (0-1)\n",
      "swow_r1_strength   : Strength of this response in SWOW R1 (first response)\n",
      "swow_r123_strength : Strength of this response in SWOW R123 (all responses)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import glob\n",
    "\n",
    "# Load SWOW strength data (R1 and R123) - they are TAB-delimited\n",
    "swow_strength_r1 = pd.read_csv(r\"C:\\Users\\peers\\Downloads\\SWOW-EN18\\strength.SWOW-EN.R1.20180827.csv\", sep=\"\\t\")\n",
    "swow_strength_r123 = pd.read_csv(r\"C:\\Users\\peers\\Downloads\\SWOW-EN18\\strength.SWOW-EN.R123.20180827.csv\", sep=\"\\t\")\n",
    "\n",
    "# Create lookup dictionaries for SWOW strength\n",
    "# Key: (cue, response), Value: strength\n",
    "swow_r1_lookup = {}\n",
    "swow_r123_lookup = {}\n",
    "\n",
    "for _, row in swow_strength_r1.iterrows():\n",
    "    key = (row['cue'], row['response'])\n",
    "    swow_r1_lookup[key] = row['R1.Strength']\n",
    "\n",
    "for _, row in swow_strength_r123.iterrows():\n",
    "    key = (row['cue'], row['response'])\n",
    "    swow_r123_lookup[key] = row['R123.Strength']\n",
    "\n",
    "print(f\"Loaded {len(swow_r1_lookup)} cue-response pairs from SWOW R1\")\n",
    "print(f\"Loaded {len(swow_r123_lookup)} cue-response pairs from SWOW R123\")\n",
    "\n",
    "# Load all model files\n",
    "model_files = sorted(glob.glob(\"../data/results/association/*_associations.csv\"))\n",
    "print(f\"\\nFound {len(model_files)} model files\")\n",
    "total_models = len(model_files)\n",
    "\n",
    "# Dictionaries to store A1 and A123 responses by cue\n",
    "all_model_a1 = {}\n",
    "all_model_a123 = {}\n",
    "\n",
    "# Load A1 and A123 responses from all models\n",
    "for model_file in model_files:\n",
    "    model_name = model_file.split(\"\\\\\")[-1].replace(\"_associations.csv\", \"\")\n",
    "    print(f\"Loading responses from {model_name}...\")\n",
    "    \n",
    "    model_data = pd.read_csv(model_file)\n",
    "    \n",
    "    for _, row in model_data.iterrows():\n",
    "        cue = str(row['cue']).lower()\n",
    "        a1_response = str(row['A1'])\n",
    "        a2_response = str(row['A2'])\n",
    "        a3_response = str(row['A3'])\n",
    "        \n",
    "        # Store A1\n",
    "        if cue not in all_model_a1:\n",
    "            all_model_a1[cue] = {}\n",
    "        all_model_a1[cue][model_name] = a1_response\n",
    "        \n",
    "        # Store all three responses for A123\n",
    "        if cue not in all_model_a123:\n",
    "            all_model_a123[cue] = []\n",
    "        \n",
    "        for resp in [a1_response, a2_response, a3_response]:\n",
    "            if resp != 'No more responses':\n",
    "                all_model_a123[cue].append(resp)\n",
    "\n",
    "# Calculate A1 strength (per unique response)\n",
    "output_data = []\n",
    "\n",
    "for cue in sorted(all_model_a1.keys()):\n",
    "    models_responses_a1 = all_model_a1[cue]\n",
    "    \n",
    "    # Get unique A1 responses for this cue\n",
    "    unique_a1s = set(models_responses_a1.values())\n",
    "    \n",
    "    for response in unique_a1s:\n",
    "        if response == 'No more responses':\n",
    "            continue\n",
    "        \n",
    "        # Count how many models gave this as A1\n",
    "        count_models_a1 = sum(1 for r in models_responses_a1.values() if r == response)\n",
    "        \n",
    "        # Calculate A1 strength\n",
    "        model_a1_strength = count_models_a1 / total_models\n",
    "        \n",
    "        # Calculate A123 strength (how often this appears in any position A1/A2/A3)\n",
    "        if cue in all_model_a123:\n",
    "            count_a123 = all_model_a123[cue].count(response)\n",
    "            total_a123_responses = len(all_model_a123[cue])\n",
    "            model_a123_strength = count_a123 / total_a123_responses if total_a123_responses > 0 else 0\n",
    "        else:\n",
    "            model_a123_strength = 0\n",
    "        \n",
    "        # Look up in SWOW\n",
    "        swow_key = (cue, response.lower())\n",
    "        swow_r1_strength = swow_r1_lookup.get(swow_key, None)\n",
    "        swow_r123_strength = swow_r123_lookup.get(swow_key, None)\n",
    "        \n",
    "        output_data.append({\n",
    "            'cue': cue,\n",
    "            'response': response,\n",
    "            'model_a1_count': count_models_a1,\n",
    "            'total_models': total_models,\n",
    "            'model_a1_strength': round(model_a1_strength, 3),\n",
    "            'model_a123_strength': round(model_a123_strength, 3),\n",
    "            'swow_r1_strength': swow_r1_strength if swow_r1_strength is not None else 'n.a.',\n",
    "            'swow_r123_strength': swow_r123_strength if swow_r123_strength is not None else 'n.a.'\n",
    "        })\n",
    "\n",
    "# Create DataFrame and sort by cue, then by model_a1_strength descending\n",
    "output_df = pd.DataFrame(output_data)\n",
    "output_df = output_df.sort_values(['cue', 'model_a1_strength'], ascending=[True, False])\n",
    "\n",
    "# Format SWOW columns for display (round if numeric)\n",
    "def format_swow(x):\n",
    "    if x == 'n.a.':\n",
    "        return 'n.a.'\n",
    "    else:\n",
    "        return round(float(x), 3)\n",
    "\n",
    "output_df['swow_r1_strength'] = output_df['swow_r1_strength'].apply(format_swow)\n",
    "output_df['swow_r123_strength'] = output_df['swow_r123_strength'].apply(format_swow)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = \"../data/results/model_a1_vs_swow_strength.csv\"\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"Consolidated A1 response strength comparison saved to:\")\n",
    "print(f\"{output_file}\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal unique cue-response pairs: {len(output_df)}\")\n",
    "print(f\"Total unique cues: {output_df['cue'].nunique()}\")\n",
    "\n",
    "print(\"\\nFirst 20 rows:\")\n",
    "print(output_df.head(20).to_string(index=False))\n",
    "\n",
    "print(\"\\n\\nColumn Explanation:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"cue                  : The cue word\")\n",
    "print(\"response             : The response from models\")\n",
    "print(\"model_a1_count       : How many models gave this as A1 (first response)\")\n",
    "print(\"total_models         : Total number of models analyzed\")\n",
    "print(\"model_a1_strength    : Proportion of models that gave this as A1 (0-1)\")\n",
    "print(\"model_a123_strength  : Proportion across all A1/A2/A3 positions (0-1)\")\n",
    "print(\"swow_r1_strength     : Strength in SWOW R1 (first response only)\")\n",
    "print(\"swow_r123_strength   : Strength in SWOW R123 (all three positions)\")\n",
    "print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
