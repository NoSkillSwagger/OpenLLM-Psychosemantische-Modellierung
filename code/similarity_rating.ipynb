{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd93d94f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import ollama\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daedb4fb",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e14b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SWOW-style prompt template\n",
    "PROMPT_TEMPLATE = \"\"\"<<SYS>>\n",
    "You MUST follow these rules:\n",
    "\n",
    "- Rate similarity on a scale from 0 to 10.\n",
    "- 0 = completely unrelated\n",
    "- 10 = identical in meaning\n",
    "- Only use integers (0-10).\n",
    "- Consider semantic similarity, not association or co-occurrence.\n",
    "- Do NOT explain your reasoning.\n",
    "- Output must be exactly one line:\n",
    "\n",
    "[word1];[word2];[rating]\n",
    "\n",
    "Example output:\n",
    "car;automobile;10\n",
    "\n",
    "<</SYS>>\n",
    "\n",
    "You will perform a word similarity rating task.\n",
    "\n",
    "Task:\n",
    "You will be given a pair of English words.\n",
    "Your job is to judge how similar their meanings are.\n",
    "\n",
    "\n",
    "Now rate the following word pair:\n",
    "\n",
    "Word 1: {w1}\n",
    "Word 2: {w2}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04348a3b",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a1b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# FUNCTION TO QUERY OLLAMA\n",
    "# ----------------------------------------------------------\n",
    "def ask_ollama(model: str, prompt: str) -> str:\n",
    "    result = ollama.generate(model=model, prompt=prompt)\n",
    "    return result['response']\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# LOAD INPUT WORDS\n",
    "# ----------------------------------------------------------\n",
    "def load_word_pairs_from_tsv(path: str):\n",
    "    \"\"\"Load word pairs from a TSV file and return as list of tuples.\"\"\"\n",
    "    pairs = []\n",
    "    with open(path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f, delimiter=\"\\t\")\n",
    "        next(reader)  \n",
    "        next(reader) # Skip first two rows\n",
    "        for row in reader:\n",
    "            if len(row) >= 2:\n",
    "                pairs.append((row[0], row[1]))\n",
    "    return pairs\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# SAVE OUTPUT\n",
    "# ----------------------------------------------------------\n",
    "def save_results(path: str, rows):\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"model\", \"w1\", \"w2\", \"rating\"])\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123fcc6d",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97609f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(pairs, output, model):\n",
    "    results = []\n",
    "    for w1, w2 in pairs:\n",
    "        prompt = PROMPT_TEMPLATE.format(w1=w1, w2=w2)\n",
    "        response = ask_ollama(model, prompt)\n",
    "        if response is None:\n",
    "            continue\n",
    "\n",
    "        # Now split by semicolon\n",
    "        parts = [p.strip() for p in response.split(\";\")]\n",
    "\n",
    "        if len(parts) != 3:\n",
    "            print(f\"Warning: Unexpected format for pair'{w1} {w2}': {response}\")\n",
    "            continue\n",
    "\n",
    "        w1, w2, rating = parts\n",
    "        results.append([model, w1, w2, rating])\n",
    "\n",
    "    save_results(output, results)\n",
    "    print(f\"Done! Saved to {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.join(\"..\", \"data\", \"datasets\", \"wordsim353.tsv\")\n",
    "word_pairs = load_word_pairs_from_tsv(input_path)\n",
    "\n",
    "models = ['qwen3:8b', 'qwen3:14b', 'qwen3:30b', 'gemma3:4b', 'gemma3:12b', 'gemma3:27b', 'llama3.1:8b']\n",
    "\n",
    "for model in models:\n",
    "    output_path = os.path.join(\"..\", \"data\", \"results\", f'{model.replace(':', '_').replace('.', '_')}_similarity_rating.csv')\n",
    "    print(f\"Starting with model: {model}\")\n",
    "    run_experiment(word_pairs, output_path, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17fda10",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cb2e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load human ratings from wordsim353\n",
    "human_data = pd.read_csv(\"../data/datasets/wordsim353.tsv\", sep=\"\\t\", comment=\"#\")\n",
    "human_data.columns = [\"w1\", \"w2\", \"human_rating\"]\n",
    "# Create a key for matching (word pairs)\n",
    "human_data[\"pair_key\"] = human_data.apply(lambda x: tuple(sorted([x[\"w1\"], x[\"w2\"]])), axis=1)\n",
    "\n",
    "# Find all model rating files\n",
    "model_files = sorted(glob.glob(\"../data/results/similarity/*.csv\"))\n",
    "\n",
    "# Start with human data\n",
    "result_df = human_data[[\"w1\", \"w2\", \"human_rating\", \"pair_key\"]].copy()\n",
    "# Add each model's ratings as a column\n",
    "for model_file in model_files:\n",
    "    model_name = model_file.split(\"\\\\\")[-1].replace(\"_similarity_rating.csv\", \"\")\n",
    "    \n",
    "    # Load model ratings\n",
    "    model_data = pd.read_csv(model_file)\n",
    "    model_data[\"pair_key\"] = model_data.apply(lambda x: tuple(sorted([x[\"w1\"], x[\"w2\"]])), axis=1)\n",
    "    \n",
    "    # Merge on pair_key, keeping only rating column\n",
    "    model_ratings = model_data[[\"pair_key\", \"rating\"]].copy()\n",
    "    model_ratings.rename(columns={\"rating\": model_name}, inplace=True)\n",
    "    \n",
    "    # Merge with result (using left join to keep all pairs)\n",
    "    result_df = result_df.merge(model_ratings, on=\"pair_key\", how=\"left\")\n",
    "    \n",
    "# Remove the pair_key column\n",
    "result_df = result_df.drop(columns=[\"pair_key\"])\n",
    "\n",
    "# Replace NaN with \"n.a.\" for display\n",
    "result_df = result_df.fillna(\"n.a.\")\n",
    "\n",
    "# Calculate mean of all models (excluding human_rating, ignoring n.a.)\n",
    "model_cols = [col for col in result_df.columns if col not in [\"w1\", \"w2\", \"human_rating\"]]\n",
    "\n",
    "def calculate_mean(row):\n",
    "    values = []\n",
    "    for col in model_cols:\n",
    "        val = row[col]\n",
    "        if val != \"n.a.\":\n",
    "            try:\n",
    "                values.append(float(val))\n",
    "            except (ValueError, TypeError):\n",
    "                pass\n",
    "    return np.mean(values) if values else np.nan\n",
    "\n",
    "result_df[\"models_mean\"] = result_df.apply(calculate_mean, axis=1)\n",
    "result_df[\"models_mean\"] = result_df[\"models_mean\"].apply(lambda x: \"n.a.\" if pd.isna(x) else round(x, 2))\n",
    "\n",
    "# Reorder columns: w1, w2, human_rating, models_mean, then all models\n",
    "final_cols = [\"w1\", \"w2\", \"human_rating\", \"models_mean\"] + model_cols\n",
    "result_df = result_df[final_cols]\n",
    "\n",
    "# Save to CSV\n",
    "result_df.to_csv(\"../data/results/similarity_results.csv\", index=False)\n",
    "print(f\"Saved detailed results to ../data/results/similarity_results.csv\")\n",
    "print(f\"Shape: {result_df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(result_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
